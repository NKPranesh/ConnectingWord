{"ast":null,"code":"import { concatenateArrayBuffers, resolvePath } from '@loaders.gl/loader-utils';\nimport { isBrowser } from '@loaders.gl/loader-utils';\nimport { writeFile } from '../fetch/write-file';\nimport { fetchFile } from '../fetch/fetch-file';\nexport async function encode(data, writer, options) {\n  if (writer.encode) {\n    return await writer.encode(data, options);\n  }\n\n  if (writer.encodeSync) {\n    return writer.encodeSync(data, options);\n  }\n\n  if (writer.encodeText) {\n    return new TextEncoder().encode(await writer.encodeText(data, options));\n  }\n\n  if (writer.encodeInBatches) {\n    const batches = encodeInBatches(data, writer, options);\n    const chunks = [];\n\n    for await (const batch of batches) {\n      chunks.push(batch);\n    }\n\n    return concatenateArrayBuffers(...chunks);\n  }\n\n  if (!isBrowser && writer.encodeURLtoURL) {\n    const tmpInputFilename = getTemporaryFilename('input');\n    await writeFile(tmpInputFilename, data);\n    const tmpOutputFilename = getTemporaryFilename('output');\n    const outputFilename = await encodeURLtoURL(tmpInputFilename, tmpOutputFilename, writer, options);\n    const response = await fetchFile(outputFilename);\n    return response.arrayBuffer();\n  }\n\n  throw new Error('Writer could not encode data');\n}\nexport function encodeSync(data, writer, options) {\n  if (writer.encodeSync) {\n    return writer.encodeSync(data, options);\n  }\n\n  throw new Error('Writer could not synchronously encode data');\n}\nexport async function encodeText(data, writer, options) {\n  if (writer.text && writer.encodeText) {\n    return await writer.encodeText(data, options);\n  }\n\n  if (writer.text && (writer.encode || writer.encodeInBatches)) {\n    const arrayBuffer = await encode(data, writer, options);\n    return new TextDecoder().decode(arrayBuffer);\n  }\n\n  throw new Error('Writer could not encode data as text');\n}\nexport function encodeInBatches(data, writer, options) {\n  if (writer.encodeInBatches) {\n    const dataIterator = getIterator(data);\n    return writer.encodeInBatches(dataIterator, options);\n  }\n\n  throw new Error('Writer could not encode data in batches');\n}\nexport async function encodeURLtoURL(inputUrl, outputUrl, writer, options) {\n  inputUrl = resolvePath(inputUrl);\n  outputUrl = resolvePath(outputUrl);\n\n  if (isBrowser || !writer.encodeURLtoURL) {\n    throw new Error();\n  }\n\n  const outputFilename = await writer.encodeURLtoURL(inputUrl, outputUrl, options);\n  return outputFilename;\n}\n\nfunction getIterator(data) {\n  const dataIterator = [{\n    table: data,\n    start: 0,\n    end: data.length\n  }];\n  return dataIterator;\n}\n\nfunction getTemporaryFilename(filename) {\n  return \"/tmp/\".concat(filename);\n}","map":{"version":3,"sources":["../../../../src/lib/api/encode.ts"],"names":["writer","batches","encodeInBatches","chunks","concatenateArrayBuffers","tmpInputFilename","getTemporaryFilename","writeFile","tmpOutputFilename","outputFilename","encodeURLtoURL","response","fetchFile","arrayBuffer","encode","dataIterator","getIterator","inputUrl","resolvePath","outputUrl","isBrowser","table","start","end","data","length"],"mappings":"AACA,SAAA,uBAAA,EAAA,WAAA,QAAA,0BAAA;AACA,SAAA,SAAA,QAAA,0BAAA;AACA,SAAA,SAAA,QAAA,qBAAA;AACA,SAAA,SAAA,QAAA,qBAAA;AAKA,OAAO,eAAA,MAAA,CAAA,IAAA,EAAA,MAAA,EAAA,OAAA,EAIiB;AACtB,MAAIA,MAAM,CAAV,MAAA,EAAmB;AACjB,WAAO,MAAMA,MAAM,CAANA,MAAAA,CAAAA,IAAAA,EAAb,OAAaA,CAAb;AACD;;AAED,MAAIA,MAAM,CAAV,UAAA,EAAuB;AACrB,WAAOA,MAAM,CAANA,UAAAA,CAAAA,IAAAA,EAAP,OAAOA,CAAP;AACD;;AAED,MAAIA,MAAM,CAAV,UAAA,EAAuB;AACrB,WAAO,IAAA,WAAA,GAAA,MAAA,CAAyB,MAAMA,MAAM,CAANA,UAAAA,CAAAA,IAAAA,EAAtC,OAAsCA,CAA/B,CAAP;AACD;;AAED,MAAIA,MAAM,CAAV,eAAA,EAA4B;AAG1B,UAAMC,OAAO,GAAGC,eAAe,CAAA,IAAA,EAAA,MAAA,EAA/B,OAA+B,CAA/B;AAGA,UAAMC,MAAa,GAAnB,EAAA;;AACA,eAAW,MAAX,KAAA,IAAA,OAAA,EAAmC;AACjCA,MAAAA,MAAM,CAANA,IAAAA,CAAAA,KAAAA;AACD;;AAED,WAAOC,uBAAuB,CAAC,GAA/B,MAA8B,CAA9B;AACD;;AAED,MAAI,CAAA,SAAA,IAAcJ,MAAM,CAAxB,cAAA,EAAyC;AAEvC,UAAMK,gBAAgB,GAAGC,oBAAoB,CAA7C,OAA6C,CAA7C;AACA,UAAMC,SAAS,CAAA,gBAAA,EAAf,IAAe,CAAf;AAEA,UAAMC,iBAAiB,GAAGF,oBAAoB,CAA9C,QAA8C,CAA9C;AAEA,UAAMG,cAAc,GAAG,MAAMC,cAAc,CAAA,gBAAA,EAAA,iBAAA,EAAA,MAAA,EAA3C,OAA2C,CAA3C;AAOA,UAAMC,QAAQ,GAAG,MAAMC,SAAS,CAAhC,cAAgC,CAAhC;AACA,WAAOD,QAAQ,CAAf,WAAOA,EAAP;AACD;;AAED,QAAM,IAAA,KAAA,CAAN,8BAAM,CAAN;AACD;AAKD,OAAO,SAAA,UAAA,CAAA,IAAA,EAAA,MAAA,EAAA,OAAA,EAAqF;AAC1F,MAAIX,MAAM,CAAV,UAAA,EAAuB;AACrB,WAAOA,MAAM,CAANA,UAAAA,CAAAA,IAAAA,EAAP,OAAOA,CAAP;AACD;;AACD,QAAM,IAAA,KAAA,CAAN,4CAAM,CAAN;AACD;AAQD,OAAO,eAAA,UAAA,CAAA,IAAA,EAAA,MAAA,EAAA,OAAA,EAIY;AACjB,MAAIA,MAAM,CAANA,IAAAA,IAAeA,MAAM,CAAzB,UAAA,EAAsC;AACpC,WAAO,MAAMA,MAAM,CAANA,UAAAA,CAAAA,IAAAA,EAAb,OAAaA,CAAb;AACD;;AAED,MAAIA,MAAM,CAANA,IAAAA,KAAgBA,MAAM,CAANA,MAAAA,IAAiBA,MAAM,CAA3C,eAAIA,CAAJ,EAA8D;AAC5D,UAAMa,WAAW,GAAG,MAAMC,MAAM,CAAA,IAAA,EAAA,MAAA,EAAhC,OAAgC,CAAhC;AACA,WAAO,IAAA,WAAA,GAAA,MAAA,CAAP,WAAO,CAAP;AACD;;AAED,QAAM,IAAA,KAAA,CAAN,sCAAM,CAAN;AACD;AAKD,OAAO,SAAA,eAAA,CAAA,IAAA,EAAA,MAAA,EAAA,OAAA,EAIuB;AAC5B,MAAId,MAAM,CAAV,eAAA,EAA4B;AAC1B,UAAMe,YAAY,GAAGC,WAAW,CAAhC,IAAgC,CAAhC;AACA,WAAOhB,MAAM,CAANA,eAAAA,CAAAA,YAAAA,EAAP,OAAOA,CAAP;AACD;;AAED,QAAM,IAAA,KAAA,CAAN,yCAAM,CAAN;AACD;AAMD,OAAO,eAAA,cAAA,CAAA,QAAA,EAAA,SAAA,EAAA,MAAA,EAAA,OAAA,EAKY;AACjBiB,EAAAA,QAAQ,GAAGC,WAAW,CAAtBD,QAAsB,CAAtBA;AACAE,EAAAA,SAAS,GAAGD,WAAW,CAAvBC,SAAuB,CAAvBA;;AACA,MAAIC,SAAS,IAAI,CAACpB,MAAM,CAAxB,cAAA,EAAyC;AACvC,UAAM,IAAN,KAAM,EAAN;AACD;;AACD,QAAMS,cAAc,GAAG,MAAMT,MAAM,CAANA,cAAAA,CAAAA,QAAAA,EAAAA,SAAAA,EAA7B,OAA6BA,CAA7B;AACA,SAAA,cAAA;AACD;;AAKD,SAAA,WAAA,CAAA,IAAA,EAA2B;AACzB,QAAMe,YAAY,GAAG,CAAC;AAACM,IAAAA,KAAK,EAAN,IAAA;AAAcC,IAAAA,KAAK,EAAnB,CAAA;AAAwBC,IAAAA,GAAG,EAAEC,IAAI,CAACC;AAAlC,GAAD,CAArB;AACA,SAAA,YAAA;AACD;;AAKD,SAAA,oBAAA,CAAA,QAAA,EAAwD;AACtD,SAAA,QAAA,MAAA,CAAA,QAAA,CAAA;AACD","sourcesContent":["import type {Writer, LoaderOptions} from '@loaders.gl/loader-utils';\nimport {concatenateArrayBuffers, resolvePath} from '@loaders.gl/loader-utils';\nimport {isBrowser} from '@loaders.gl/loader-utils';\nimport {writeFile} from '../fetch/write-file';\nimport {fetchFile} from '../fetch/fetch-file';\n\n/**\n * Encode loaded data into a binary ArrayBuffer using the specified Writer.\n */\nexport async function encode(\n  data: any,\n  writer: Writer,\n  options?: LoaderOptions\n): Promise<ArrayBuffer> {\n  if (writer.encode) {\n    return await writer.encode(data, options);\n  }\n\n  if (writer.encodeSync) {\n    return writer.encodeSync(data, options);\n  }\n\n  if (writer.encodeText) {\n    return new TextEncoder().encode(await writer.encodeText(data, options));\n  }\n\n  if (writer.encodeInBatches) {\n    // Create an iterator representing the data\n    // TODO - Assumes this is a table\n    const batches = encodeInBatches(data, writer, options);\n\n    // Concatenate the output\n    const chunks: any[] = [];\n    for await (const batch of batches) {\n      chunks.push(batch);\n    }\n    // @ts-ignore\n    return concatenateArrayBuffers(...chunks);\n  }\n\n  if (!isBrowser && writer.encodeURLtoURL) {\n    // TODO - how to generate filenames with correct extensions?\n    const tmpInputFilename = getTemporaryFilename('input');\n    await writeFile(tmpInputFilename, data);\n\n    const tmpOutputFilename = getTemporaryFilename('output');\n\n    const outputFilename = await encodeURLtoURL(\n      tmpInputFilename,\n      tmpOutputFilename,\n      writer,\n      options\n    );\n\n    const response = await fetchFile(outputFilename);\n    return response.arrayBuffer();\n  }\n\n  throw new Error('Writer could not encode data');\n}\n\n/**\n * Encode loaded data into a binary ArrayBuffer using the specified Writer.\n */\nexport function encodeSync(data: any, writer: Writer, options?: LoaderOptions): ArrayBuffer {\n  if (writer.encodeSync) {\n    return writer.encodeSync(data, options);\n  }\n  throw new Error('Writer could not synchronously encode data');\n}\n\n/**\n * Encode loaded data to text using the specified Writer\n * @note This is a convenience function not intended for production use on large input data.\n * It is not optimized for performance. Data maybe converted from text to binary and back.\n * @throws if the writer does not generate text output\n */\nexport async function encodeText(\n  data: any,\n  writer: Writer,\n  options?: LoaderOptions\n): Promise<string> {\n  if (writer.text && writer.encodeText) {\n    return await writer.encodeText(data, options);\n  }\n\n  if (writer.text && (writer.encode || writer.encodeInBatches)) {\n    const arrayBuffer = await encode(data, writer, options);\n    return new TextDecoder().decode(arrayBuffer);\n  }\n\n  throw new Error('Writer could not encode data as text');\n}\n\n/**\n * Encode loaded data into a sequence (iterator) of binary ArrayBuffers using the specified Writer.\n */\nexport function encodeInBatches(\n  data: any,\n  writer: Writer,\n  options?: LoaderOptions\n): AsyncIterable<ArrayBuffer> {\n  if (writer.encodeInBatches) {\n    const dataIterator = getIterator(data);\n    return writer.encodeInBatches(dataIterator, options);\n  }\n  // TODO -fall back to atomic encode?\n  throw new Error('Writer could not encode data in batches');\n}\n\n/**\n * Encode data stored in a file (on disk) to another file.\n * @note Node.js only. This function enables using command-line converters as \"writers\".\n */\nexport async function encodeURLtoURL(\n  inputUrl,\n  outputUrl,\n  writer: Writer,\n  options\n): Promise<string> {\n  inputUrl = resolvePath(inputUrl);\n  outputUrl = resolvePath(outputUrl);\n  if (isBrowser || !writer.encodeURLtoURL) {\n    throw new Error();\n  }\n  const outputFilename = await writer.encodeURLtoURL(inputUrl, outputUrl, options);\n  return outputFilename;\n}\n\n/**\n * @todo TODO - this is an unacceptable hack!!!\n */\nfunction getIterator(data) {\n  const dataIterator = [{table: data, start: 0, end: data.length}];\n  return dataIterator;\n}\n\n/**\n * @todo Move to utils\n */\nfunction getTemporaryFilename(filename: string): string {\n  return `/tmp/${filename}`;\n}\n"]},"metadata":{},"sourceType":"module"}